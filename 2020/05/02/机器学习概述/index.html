<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta name="keywords" content="" />
  <meta name="description" content="" />
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://busuanzi.ibruce.info">
  <link rel="dns-prefetch" href="https://at.alicdn.com">
  
  
  
  <link rel="stylesheet" type="text/css" href="/./style/main.css">
	<link rel="shortcut icon" href="" title="Favicon">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
	<title>机器学习概述</title>
  
  
<meta name="generator" content="Hexo 4.2.0"></head>
<body>
  <canvas id="pattern-placeholder" height="230"></canvas>
<div class="navbar-header">
  <a class="blog-title" href="/">bernardo</a>
  <a class="face-img" href="/">
    <img src="">
  </a>
</div>
<main>
  <div class="article-title">
    
  
  <h1 class="title">
    机器学习概述
  </h1>
  


    <ul class="article-info">
      <li>
        发布
        <time datetime="2020-05-02T03:08:42.240Z" itemprop="datePublished">2020-05-02</time>
      </li>
      <li>
        
      </li>
      <li id="busuanzi_container_page_pv">
        阅读 <span id="busuanzi_value_page_pv"></span>
      </li>
    </ul>
  </div>
  <div class="container">
    <div class="article">
      <div class="content">
        
        <h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>&#160; &#160; &#160; &#160;机器学习，英文名叫<font color=blue><strong>Machine Learning</strong></font>，它的广义定义为通过使用<font color=red><strong>经验（experience）</strong></font>来提高算法性能并对未知数据做精准预测的计算方法。经验（experience）指的是能够为学习者提供有用的历史信息和数据，收集数据并做可行性分析。这些<font color = red><strong>数据（data）</strong></font>可能来自于有标签的训练集，或者是通过环境交互下的其他类型的信息，数据的好坏和数量多少对于学习者预测的成功与否起着至关重要的作用。</p>
<p>&#160; &#160; &#160; &#160;机器学习是由设计有效和精确的算法组成的，在其他的科学领域，衡量算法好坏的重要标准就是其<font color = red><strong>时间复杂度</strong></font>和<font color = red><strong>空间复杂度</strong></font>，但在机器学习领域我们需要额外的对样本的复杂度进行评估，需要算法去学习一系列的概念。理论分析表明，算法是由所分析概念的复杂性和样本的大小共同决定的。</p>
<p>&#160; &#160; &#160; &#160;算法的是否成功取决于所使用数据，因此，机器学习与数据分析和统计理论是密不可分的。机器学习是由数据所驱动的，是计算机的基本概念与<font color = red><strong>统计</strong></font>、<font color = red><strong>概率</strong></font>和<font color = red><strong>优化</strong></font>相结合的产物。</p>
<h1 id="二、机器学习的应用和相关问题"><a href="#二、机器学习的应用和相关问题" class="headerlink" title="二、机器学习的应用和相关问题"></a>二、机器学习的应用和相关问题</h1><p>&#160; &#160; &#160; &#160;机器学习理论现在已经成功的应用到如下的领域：</p>
<ul>
<li>文本分类</li>
<li>自然语言处理（NLP）</li>
<li>语音识别、语音合成、说话人检测</li>
<li>光学符号识别（COR）</li>
<li>计算生物学应用</li>
<li>计算机视觉（图片识别、人脸检测）</li>
<li>欺诈检测和网络入侵</li>
<li>各种游戏（象棋、围棋）</li>
<li>自助车辆控制（机器人，自动导航）</li>
<li>医学制药</li>
<li>推荐系统、搜索引擎、信息提取系统</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200328172810570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2J3cWlhbmc=,size_16,color_FFFFFF,t_70#pic_center" alt="机器学习的主要应用领域"></p>
<p>&#160; &#160; &#160; &#160;机器学习主要应用于以下几个领域：</p>
<ul>
<li><font color=red><strong>分类（Classification）</strong></font>：为每一项分配一个类别。例如，新闻分类可以分为政治类新闻、经济类新闻、体育类新闻等等。图片分类可以分为风景类图片、肖像类图片、动.物类图片等等。有些分类比较少，有些分的类别就会比较多，甚至是无限分类。</li>
<li><font color=red><strong>回归（regression）</strong></font>：为每一项预测一个真实值。例如对股票行情的预测或者明天下雨的概率。对于错误分类的惩罚取决于样本真实值和预测值的差值，和分类问题不同的是，各个类别之间没有关联性。</li>
<li><font color=red><strong>排序（ranking）</strong></font>：根据一些标准为每一项进行排序。例如，网页搜索，返回与搜索查询相关的网页。在信息提取或自然语言处理系统的设计过程中，还会出现许多类似的排序问题。</li>
<li><font color=red><strong>聚类（Clustering）</strong></font>：将每一项划分到性质相同的区域。聚类经常被用于较大的数据集中。例如，对于社会网络的分析，聚类算法尝试着在很大一部分人群中分辨相同特点的人。</li>
<li><font color=red><strong>降维（Dimensionality reduction）</strong></font>或 <font color=red><strong>流形学习（manifold learning）</strong></font>：将一些项的初始表示转化为这些项的低维表示，并且保存这些项初始表示时的特征。例如在计算机视觉中处理数字图像。</li>
</ul>
<p>&#160; &#160; &#160; &#160;机器学习的主要实践目标就是对未知项甚至是更大规模的问题设计高效和鲁棒性的算法产生精准的预测，由此便产生了大量的算法和理论性问题。</p>
<h1 id="三、机器学习的定义和相关术语"><a href="#三、机器学习的定义和相关术语" class="headerlink" title="三、机器学习的定义和相关术语"></a>三、机器学习的定义和相关术语</h1><p>&#160; &#160; &#160; &#160;本部分将使用垃圾邮件检测作为一个标准的例子来阐述机器学习的一些定义和相关术语。</p>
<ul>
<li><font color=red><strong>示例（Examples）</strong></font>：用于学习或评估的数据项或实例。在垃圾邮件检测问题中，这些示例就是我们将用于学习和测试的邮件集合。</li>
<li><font color=red><strong>特征（Features）</strong></font>：示例属性的集合，经常用向量来表示，与示例相关联。对于邮件，一些相关的特征可能是信息的长度、发送者、文件中的关键句子等等。</li>
<li><font color=red><strong>标签（labels）</strong></font>：示例的类别或者数值。在分类问题中，示例经常被分配特定的类别。例如，二分类中的垃圾邮件和非垃圾邮件。在回归问题中，项目被分配实时标签。</li>
<li><font color=red><strong>训练样本（Training sample）</strong></font>：被用来训练一个学习算法的示例。在垃圾邮件分类问题中，训练样本是由一系列的带有标签的邮件示例组成的。</li>
<li><font color=red><strong>验证样本（Validation sample）</strong></font>：当使用有标签数据训练学习算法时，那些用于调节算法参数的示例。学习算法通常有一个或多个自由参数，验证样例用于为这些模型参数选择适当的值。</li>
<li><font color=red><strong>测试样本（Test sample）</strong></font>：用于评价算法性能的示例。测试样本与训练样本和验证样本不放在一起，在算法的学习训练阶段不发挥作用。在垃圾邮件分类问题中，测试样本由一组邮件组成，学习算法需要基于特征来预测邮件标签（是否为垃圾邮件）。然后将这些预测值与测试样本的真实标签进行比较，来评估算法的性能。</li>
<li><font color=red><strong>损失函数（Loss function）</strong></font>：用来计算示例的预测标签和真实标签之间的差异或损失的函数。 可以用$\mathcal{Y}$来定义样本标签的集合，样本标签的所有可能的预测集合用$\mathcal{Y}’$来表示，损失函数$L$就是这样一个映射：$\mathcal{Y}\times\mathcal{Y}’\rightarrow R_+$。在大多数情况下，$\mathcal{Y}=\mathcal{Y}’$，损失函数是有界的，但这些条件并不总是成立。常用的损失函数包括0-1损失，$L(y,y’)=1_{y’\ne y}$在${-1,+1}\times{-1,+1}$的范围上定义。平方差损失是$L(y,y’)=(y’−y)^2$在$I\times I$上的定义，$I \subseteq \mathbb{R}$通常是一个有界的区间。</li>
<li><font color=red><strong>假设集（Hypothesis set）</strong></font>：一组函数将特征(特征向量)映射到一组标签$\mathcal{Y}$上去。本例中，一系列的函数有可能就是将邮件的特征映射到 $\mathcal{Y} = {SPAM,non-SPAM}$。它们可以是线性函数，将电子邮件的特征向量映射为分数$(\mathcal{Y}’= R)$，高分的垃圾邮件比低分的更具有指示性。</li>
</ul>
<p>&#160; &#160; &#160; &#160;首先，<font color=#00BFFF><strong>将样例随机划分为训练样本、验证样本和测试样本</strong></font>。验证样本的多少可以取决于算法中的自由参数的多少，当示例数相对来说较少的话，分配训练样本的数量一般要多于测试样本，因为算法的学习性能是直接受训练样本的多少导致的。</p>
<p>&#160; &#160; &#160; &#160;然后，需要<font color=#00BFFF><strong>找到与样例相关的特征</strong></font>，有利的特征能够加快学习算法的训练反之则会对学习算法造成误导，所以这一步是至关重要的。这就要看是否对这种样例的特征值的选取有足够的了解，这样会对最终算法的性能造成巨大的影响。</p>
<p>&#160; &#160; &#160; &#160;现在，需要<font color=#00BFFF><strong>用选好的特征通过固定不同的自由参数值来训练学习算法</strong></font>。对于这些参数的每一个值，算法都会从假设集中选择一个不同的假设。我们从这些假设中选择一个在验证样本上表现最好的假设。最后利用该假设对测试样本中的样本标签进行预测。算法的性能是通过使用相应的损失函数(例如垃圾邮件检测任务中的0-1损失)来比较预测的标签和真实的标签的差值。</p>
<p>&#160; &#160; &#160; &#160;所以<font color=#00BFFF><strong>评价一个机器学习算法的好坏不是看它在训练样本中的精确度而是看它在测试样本中的预测精准度</strong></font>。甚至有的学习算法已经能够在训练样本中实现了0的训练误差却在测试样本中的表现出很差的性能。这种学习算法仅仅是对有限个样本的分布的一个机械的记忆，并不适用于对未知数据的预测，这种算法的<font color=red><strong>泛化能力（generalization）</strong></font>是极差的。具体问题的讨论将在以后的博文中论述。</p>
<h1 id="四、交叉验证"><a href="#四、交叉验证" class="headerlink" title="四、交叉验证"></a>四、交叉验证</h1><p>&#160; &#160; &#160; &#160;在实践中，可用的有标签样本数量通常比较少，不能留出足够的验证样本，这样会留下不足的训练数据量。可以使用<font color=red><strong>$n$折交叉验证（n-fold cross-validation）</strong></font>，用于利用标记数据进行模型选择(算法自由参数的选择)和训练。</p>
<p>&#160; &#160; &#160; &#160;让$\theta$表示算法中自由参数的向量。方法是将样本集$S$划分为$n$个子样本集，每个样本集中样本数量是$m$个，其中的第$i$折的样本集就是$((x_{i1},y_{i1}),…,(x_{im},y_{im}))$。训练方法就是每次将除了第$i$个样本集作为测试样本外，其余的$n-1$个样本集作为训练集对学习算法进行训练。产生了一个假设$h_i$后用第$i$个样本集进行测试，最后参数$\theta$用$h_i$的平均值作为评估，叫做<font color=red><strong>交叉验证误差（ cross-validation error）</strong></font>，相关的公式定义为：</p>
<p>$$\widehat{R}<em>{CV}(\theta)=\frac{1}{n}\sum</em>{i=1}^n\frac{1}{m_i}\sum_{j=1}^{m_i}L(h_i(x_{ij},y_{ij}))$$</p>
<p> ，其中$\frac{1}{m_i}\sum_{j=1}^{m_i}L(h_i(x_{ij},y_{ij}))$是第$i$折中假设$h_i$的误差。</p>
<p>&#160; &#160; &#160; &#160;$n$通常选择在5至10之间，最后通过$\widehat{R}_{CV}(\theta)$计算出$\theta$的最小值$\theta_0$。在接下来，算法用于对测试样本进行检测的过程中则全部将$\theta_0$来替代$\theta$值。</p>
<p>&#160; &#160; &#160; &#160;$n$折交叉验证的特殊情况是当$n=m$时的情况，这种情况叫做<font color=red><strong>留一交叉验证（eave-one-out cross-validation）</strong></font>，也就是说每次的测试集中只有$1$个样本，在以后的博文中我会写到，留一平均误差是一个算法的平均误差的无偏估计。一般来说，留一误差的计算对计算机来说是花销还是蛮大的，因为它需要对$m-1$个样本训练$n$次，但对于某些算法有可能会存在一些简便运算。</p>
<table>
    <tr>
        <td><center><img src="https://img-blog.csdnimg.cn/20200328172417913.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2J3cWlhbmc=,size_16,color_FFFFFF,t_70">n折交叉验证</center>
        <td><center><img src="https://img-blog.csdnimg.cn/2020032817250251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2J3cWlhbmc=,size_16,color_FFFFFF,t_70">随着样本数量增大损失下降</center>
    </td>




<h1 id="五、机器学习的学习场景"><a href="#五、机器学习的学习场景" class="headerlink" title="五、机器学习的学习场景"></a>五、机器学习的学习场景</h1><p>&#160; &#160; &#160; &#160;下面将简短的描述一下机器学习的学习场景。这些场景在学习者可获得的训练数据类型、接收训练数据的顺序和方法以及用于评估学习算法的测试数据方面有所不同。</p>
<ul>
<li><font color=red><strong>监督学习（Supervised learning）</strong></font>：<font color=#00BFFF><strong>学习者接收一组带有标签的样例作为训练数据，并对所有未知数据进行预测</strong></font>。这是与分类、回归和排序问题相关的最常见场景。前一节讨论的垃圾邮件检测问题是监督学习的一个实例。</li>
<li><font color=red><strong>无监督学习（自监督）（Unsupervised learning）</strong></font>：<font color=#00BFFF><strong>学习者接收到一组没有标签的数据并对所有未知数据进行预测</strong></font>。这种情乱下，没有标记的样例很难对学习者所学到的算法模型的性能进行定量的评估。聚类和降维是无监督学习问题的一个例子。（博主本人在研一的时候曾经搞过一段时间的自监督，后来换了课题）</li>
<li><font color=red><strong>半监督学习（Semi-supervised learning）</strong></font>：<font color=#00BFFF><strong>学习者收到一个既有带标签又有不带标签的数据训练样本，并对所有不可见点进行预测</strong></font>。半监督学习在一种未标记的数据很容易获得但是有标签数据很难获取的情况下常见。应用程序中出现包括分类、回归或排序工作，都可以作为半监督学习的实例。希望通过学习者接收到未标记数据的分布能够帮助他们获得比在监督环境下更好的性能体现。分析在什么条件下才能真正实现这一点，是许多现代理论和应用机器学习研究的主题。</li>
<li><font color=red><strong>转导推理（Transductive inference）</strong></font>：在半监督的情况下，学习者收到一个有标记的训练样本和一组没有标记的测试点。然而，转换推理的目的是<font color=#00BFFF><strong>仅预测某些特定测试点的标签</strong></font>。转换推理似乎是一项更简单的任务，并且与各种现代应用程序中遇到的场景相匹配。然而，就像在半监督的情况下一样，在这种情况下可以获得更好性能的假设是还没有完全解决的研究问题。</li>
<li><font color=red><strong>线上学习（On-line learning）</strong></font>：与前面的场景相比，<font color=#00BFFF><strong>在线场景涉及多个回合，并且训练和测试阶段是混合的</strong></font>。在每一轮，学习者接收到无标签的训练点，对其进行预测并对照该点的真实标签，计算损失。设置在线集的目的是<font color=#00BFFF><strong>最小化所有轮的累计损失</strong></font>。与前面讨论的有所不同，在线学习没有分布假设。事实上，在这个场景中，实例及其标签可能是相反的选择。</li>
<li><font color=red><strong>强化学习（Reinforcement learning）</strong></font>：在强化学习中<font color=#00BFFF><strong>训练阶段和测试阶段也是混合在一起的</strong></font>。为了收集信息，学习者积极的与环境相互作用，在某些情况下还会影响环境，并且还会在每次交互中得到奖励。学习者的目标是在与环境交互的过程中或者一系列的活动中最大化他的回报。然而，环境并没有提供长期的奖励反馈，学习者面临着<font color=#00BFFF><strong>探索与利用（exploration versus exploitation）</strong></font>的两难境地，因为他必须在探索未知的行为以获得更多的信息和利用已经收集的信息之间做出选择。</li>
<li><font color=red><strong>主动学习（Active learning）</strong></font>：学习者自适应地或交互式地收集训练示例，通常通过查询oracle来请求新点的标签。主动学习的目标是<font color=#00BFFF><strong>实现与标准监督学习场景相当的性能，但是使用更少的标记示例</strong></font>。主动学习通常用于标签获取昂贵的应用程序，例如计算生物学应用程序。</li>
</ul>
<h1 id="六、本系列博文的后序发展"><a href="#六、本系列博文的后序发展" class="headerlink" title="六、本系列博文的后序发展"></a>六、本系列博文的后序发展</h1><p>&#160; &#160; &#160; &#160;在今后，我会陆续更新机器学习有关的博文，讲述机器学习相关算法，下述是一个后序发展的主线。</p>
<ul>
<li><strong>概率近似正确（PAC）学习框架</strong>（probably approximately correct）；<strong>有限假设集的学习保证</strong>（ learning guarantees for finite hypothesis sets）。</li>
<li><strong>无限假设集的学习保证</strong>（learning guarantees for infinite hypothesis sets），<strong>Rademacher复杂度</strong>（Rademacher complexity），<strong>VC维</strong>（VC-dimension）。</li>
<li><strong>支持向量机</strong>（SVMs），<strong>间隔理论</strong>（margin theory）。</li>
<li><strong>核函数</strong>（kernel methods），<strong>正定对称核</strong>（positive definite symmetric kernels），<strong>表示定理</strong>（ representer theorem），<strong>有理核</strong>（rational kernels）。</li>
<li><strong>提升方法</strong>（Boosting），<strong>经验误差分析</strong>（analysis of empirical error），<strong>泛化误差</strong>（ generalization error），<strong>间隔边界</strong>（margin bounds）。</li>
<li><strong>在线学习</strong>（online learning），<strong>误差边界</strong>（ mistake bounds），<strong>加权多数算法</strong>（ the weighted majority algorithm），<strong>指数加权平均算法</strong>（the exponential weighted average algorithm），<strong>感知器</strong>（Perceptron）和<strong>Winnow算法</strong>（Winnow algorithms）。</li>
<li><strong>多类别分类</strong>（multi-class classification），<strong>多类别支持向量机</strong>（multi-class SVMs），<strong>多类别提升方法</strong>（multi-class boosting），<strong>一对多</strong>（ one-versus-all），<strong>一对一</strong>（one-versus-one），<strong>错误修正方法</strong>（ error-correction methods）。</li>
<li><strong>排序</strong>（ranking），<strong>SVMs排序</strong>（ ranking with SVMs），<strong>RankBoost</strong>，<strong>二部排序（bipartite ranking）</strong>，<strong>基于偏好的排序</strong>（preference-based ranking）。</li>
<li><strong>回归</strong>（regression），<strong>线性回归</strong>（ linear regression），<strong>内核岭回归</strong>（kernel ridge regression），<strong>支持向量回归</strong>（support vector regression），<strong>Lasso</strong>。</li>
<li><strong>稳定性分析</strong>（stability-based analysis），<strong>分类和回归的应用</strong>。</li>
<li><strong>降维</strong>（dimensionality reduction），<strong>主成分分析</strong>（principal component analysis），<strong>核主成分分析</strong>（kernel PCA），<strong>Johnson-Lindenstrauss引理</strong>。</li>
<li><strong>学习自动机</strong>（learning automata），<strong>语言</strong>（languages）。</li>
<li><strong>强化学习</strong>（reinforcement learning），<strong>马尔科夫决策过程</strong>（ Markov decision processes），<strong>计划和学习问题</strong>（planning and learning problems）。</li>
</ul>

      </div>
        <div class="support-author">
          <p>感谢您的阅读。 🙏
          <a href="" target="_blank">关于转载请看这里</a>
            <!--<a class="btn-pay"  href="#pay-modal">¥ 打赏支持</a>-->
          </p>
        </div>
        <!--
            <div class="like ">
              <div class="like-button">
                <a id="like-note" href="">
                  <i class="icon-heart"></i>喜欢
                </a>
              </div>
              <span id="likes-count">256</span>
            </div>
        -->
        <div class="otherLink">
          <div class="previous">
          </div>
          <div class="next">
          </div>
        </div>
        <div class="comments" id="comments">
          

        </div>
      </div>
    </div>
   </div>
</main>
<div class="footer">
  <div class="info">
    <p>
    <a href="https://hexo.io" target="_blank" rel="noopener"> Hexo </a> 强力驱动 |
      <a href="https://github.com/Youthink/hexo-themes-yearn" target="_blank" rel="noopener"> Yearn </a>
      主题
    </p>
    <p>&copy; </p>
  </div>
</div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script>//console
  var consoleConfig = ''.split(',');
  var canConsole = ;
  var consoleInfo = (function(consoleConfig) {
  if (!canConsole || !consoleConfig || consoleConfig.length < 1) {
    return;
  }
  var consoleColor = '#6190e8';
  var _console;
  var backgroundTextStyle = 'padding: 1px 5px;color: #fff;background: ' + consoleColor + ';'
  var textStyle = 'color: ' + consoleColor + ';';

  consoleConfig.map(o => {
    var num = (o.match(/%c/g) || []).length;
    if(/^http(s)?:\/\//.test(o)) {
      console.log('%c     ', 'background: url(' + o + ') no-repeat left center;font-size: 180px;');
      return;
    }
    if (num > 0) {
      var logArguments = [];
      for (var i = 0; i < num; i++) {
        if (i % 2 === 0) {
          logArguments.push(backgroundTextStyle);
        } else {
          logArguments.push(textStyle);
        }
      }
      (_console = console).log.apply(_console, ['%c' + o, textStyle].concat(logArguments));
      return;
    }
    console.log('%c' + o, textStyle);
  });
}(consoleConfig));</script><script type="text/javascript" src="/./js/main.js"></script>

  <script src="//at.alicdn.com/t/font_159214_mvtxvg9me9.js"></script>
</body>
</html>
